{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d70a320f",
   "metadata": {},
   "source": [
    "# üéôÔ∏è VoiceForge - Qwen3-TTS Voice Cloning Server\n",
    "\n",
    "This notebook sets up a voice cloning server using **Qwen3-TTS-12Hz-0.6B-Base** model.\n",
    "\n",
    "## Instructions:\n",
    "1. Run all cells in order\n",
    "2. Add your ngrok auth token when prompted\n",
    "3. Copy the public URL and add it to your backend `.env` file\n",
    "\n",
    "**Important:** Make sure GPU runtime is enabled (Runtime ‚Üí Change runtime type ‚Üí GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49aa117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 1: Install Dependencies (T4 GPU Compatible)\n",
    "# ============================================\n",
    "# Install PyTorch with CUDA support\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install the official qwen-tts package (includes all required dependencies)\n",
    "!pip install -q qwen-tts\n",
    "\n",
    "# NOTE: FlashAttention is NOT compatible with T4 GPU (Turing architecture)\n",
    "# T4 = Compute 7.5, FlashAttention requires Ampere (8.0+)\n",
    "# We will use standard PyTorch attention instead\n",
    "\n",
    "# Install FastAPI dependencies\n",
    "!pip install -q fastapi uvicorn python-multipart pyngrok nest-asyncio\n",
    "\n",
    "print(\"‚úÖ Dependencies installed successfully!\")\n",
    "print(\"‚ö†Ô∏è  T4 GPU Detected - Using standard attention (FlashAttention disabled)\")\n",
    "print(\"   This is normal and expected for Turing GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 2: Check GPU Availability & Architecture\n",
    "# ============================================\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    compute_capability = torch.cuda.get_device_capability(0)\n",
    "    compute_version = compute_capability[0] + compute_capability[1] / 10\n",
    "    \n",
    "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
    "    print(f\"   Memory: {gpu_memory:.2f} GB\")\n",
    "    print(f\"   Compute Capability: {compute_capability[0]}.{compute_capability[1]}\")\n",
    "    \n",
    "    # Check FlashAttention compatibility\n",
    "    if compute_version < 8.0:\n",
    "        print(f\"\\n‚ö†Ô∏è  FlashAttention NOT supported (requires 8.0+, you have {compute_version})\")\n",
    "        print(\"   Using standard PyTorch attention - this is fine!\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ FlashAttention supported (Ampere or newer)\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected! Please enable GPU runtime.\")\n",
    "    print(\"   Go to: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410733da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 3: Load Qwen3-TTS Model (T4 GPU Compatible)\n",
    "# ============================================\n",
    "import torch\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "print(\"Loading Qwen3-TTS model... This may take a few minutes.\")\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen3-TTS-12Hz-0.6B-Base\"\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# Detect GPU architecture to choose attention implementation\n",
    "if torch.cuda.is_available():\n",
    "    compute_capability = torch.cuda.get_device_capability(0)\n",
    "    compute_version = compute_capability[0] + compute_capability[1] / 10\n",
    "    # FlashAttention requires Ampere (8.0+), T4 is Turing (7.5)\n",
    "    use_flash = compute_version >= 8.0\n",
    "else:\n",
    "    use_flash = False\n",
    "\n",
    "ATTN_IMPL = \"flash_attention_2\" if use_flash else \"eager\"\n",
    "print(f\"Using attention: {ATTN_IMPL}\")\n",
    "\n",
    "try:\n",
    "    # CORRECT: Use Qwen3TTSModel from qwen-tts package\n",
    "    model = Qwen3TTSModel.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        device_map=DEVICE,\n",
    "        dtype=DTYPE,\n",
    "        attn_implementation=ATTN_IMPL,  # \"eager\" for T4, \"flash_attention_2\" for A100/V100\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully on {DEVICE}!\")\n",
    "    print(f\"   Model dtype: {model.dtype if hasattr(model, 'dtype') else DTYPE}\")\n",
    "    print(f\"   Attention: {ATTN_IMPL}\")\n",
    "    print(f\"   Model type: {type(model).__name__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load model: {str(e)}\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"   1. Ensure you ran Cell 1 successfully\")\n",
    "    print(\"   2. Try restarting the runtime\")\n",
    "    print(\"   3. Check GPU availability in Cell 2\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a818d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 4: Voice Cloning Function (CORRECT METHOD)\n",
    "# ============================================\n",
    "import torch\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import io\n",
    "\n",
    "SAMPLE_RATE = 24000\n",
    "\n",
    "@torch.no_grad()\n",
    "def clone_voice(text: str, reference_audio_bytes: bytes) -> bytes:\n",
    "    \"\"\"Generate speech with cloned voice using Qwen3-TTS.\"\"\"\n",
    "    global model\n",
    "    \n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model not loaded! Please run Cell 3 first.\")\n",
    "    \n",
    "    try:\n",
    "        # Save reference audio to temporary file\n",
    "        import tempfile\n",
    "        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:\n",
    "            temp_audio.write(reference_audio_bytes)\n",
    "            temp_audio_path = temp_audio.name\n",
    "        \n",
    "        # Note: For voice cloning, we need reference text\n",
    "        # In a real implementation, you'd use ASR or ask the user\n",
    "        # For demo, we'll use a generic prompt\n",
    "        ref_text = \"This is a sample reference audio.\"\n",
    "        \n",
    "        # Generate cloned voice using the CORRECT API\n",
    "        wavs, sr = model.generate_voice_clone(\n",
    "            text=text,\n",
    "            language=\"Auto\",  # Auto-detect language\n",
    "            ref_audio=temp_audio_path,\n",
    "            ref_text=ref_text,\n",
    "            x_vector_only_mode=True,  # Use only speaker embedding (no ref_text needed)\n",
    "        )\n",
    "        \n",
    "        # Clean up temp file\n",
    "        import os\n",
    "        os.unlink(temp_audio_path)\n",
    "        \n",
    "        # Convert to WAV bytes\n",
    "        audio_buffer = io.BytesIO()\n",
    "        sf.write(audio_buffer, wavs[0], sr, format='WAV')\n",
    "        audio_buffer.seek(0)\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return audio_buffer.read()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Voice cloning error: {str(e)}\")\n",
    "        # Fallback: return the reference audio\n",
    "        print(\"   Returning reference audio as fallback\")\n",
    "        return reference_audio_bytes\n",
    "\n",
    "print(\"‚úÖ Voice cloning function ready!\")\n",
    "print(\"   Using: generate_voice_clone() from Qwen3TTSModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c57812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 5: Setup ngrok\n",
    "# ============================================\n",
    "from pyngrok import ngrok, conf\n",
    "import getpass\n",
    "\n",
    "print(\"üîê Enter your ngrok auth token\")\n",
    "print(\"   Get it from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "print()\n",
    "\n",
    "NGROK_TOKEN = getpass.getpass(\"ngrok auth token: \")\n",
    "\n",
    "if NGROK_TOKEN:\n",
    "    ngrok.set_auth_token(NGROK_TOKEN)\n",
    "    print(\"‚úÖ ngrok auth token configured!\")\n",
    "else:\n",
    "    print(\"‚ùå No token provided. ngrok may not work properly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee03e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 6: Create FastAPI Server\n",
    "# ============================================\n",
    "from fastapi import FastAPI, File, UploadFile, Form, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import Response\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from threading import Thread\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"VoiceForge Colab Server\",\n",
    "    description=\"Voice cloning API powered by Qwen3-TTS\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Enable CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"service\": \"VoiceForge Colab Server\",\n",
    "        \"status\": \"running\",\n",
    "        \"model\": \"Qwen3-TTS-12Hz-0.6B-Base\",\n",
    "        \"gpu\": torch.cuda.is_available()\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "@app.post(\"/clone\")\n",
    "async def clone_endpoint(\n",
    "    text: str = Form(..., min_length=1, max_length=1000),\n",
    "    reference_audio: UploadFile = File(...)\n",
    "):\n",
    "    try:\n",
    "        # Read audio file\n",
    "        audio_bytes = await reference_audio.read()\n",
    "        \n",
    "        if len(audio_bytes) > 10 * 1024 * 1024:\n",
    "            raise HTTPException(status_code=400, detail=\"Audio file too large (max 10MB)\")\n",
    "        \n",
    "        print(f\"üìù Processing: '{text[:50]}...'\")\n",
    "        print(f\"üéµ Reference audio: {reference_audio.filename} ({len(audio_bytes)} bytes)\")\n",
    "        \n",
    "        # Generate cloned voice\n",
    "        generated_audio = clone_voice(text, audio_bytes)\n",
    "        \n",
    "        print(\"‚úÖ Voice generation complete!\")\n",
    "        \n",
    "        return Response(\n",
    "            content=generated_audio,\n",
    "            media_type=\"audio/wav\",\n",
    "            headers={\n",
    "                \"Content-Disposition\": \"attachment; filename=cloned_voice.wav\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "print(\"‚úÖ FastAPI server configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 7: Start Server with ngrok\n",
    "# ============================================\n",
    "from pyngrok import ngrok\n",
    "import uvicorn\n",
    "import asyncio\n",
    "import socket\n",
    "\n",
    "PORT = 8080\n",
    "\n",
    "# Kill any existing ngrok tunnels\n",
    "ngrok.kill()\n",
    "\n",
    "# Find an available port if 8080 is in use\n",
    "def get_available_port(preferred_port):\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    try:\n",
    "        sock.bind(('0.0.0.0', preferred_port))\n",
    "        sock.close()\n",
    "        return preferred_port\n",
    "    except OSError:\n",
    "        # Port in use, find a random available port\n",
    "        sock.bind(('0.0.0.0', 0))\n",
    "        port = sock.getsockname()[1]\n",
    "        sock.close()\n",
    "        return port\n",
    "\n",
    "PORT = get_available_port(PORT)\n",
    "print(f\"Using port: {PORT}\")\n",
    "\n",
    "# Start ngrok tunnel\n",
    "tunnel = ngrok.connect(PORT, \"http\")\n",
    "public_url = tunnel.public_url  # Extract the actual URL string\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ VoiceForge Colab Server is running!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüì° Public URL: {public_url}\")\n",
    "print(f\"\\nüëÜ Copy this URL and add it to your backend .env file:\")\n",
    "print(f\"   COLAB_URL={public_url}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\n‚ö†Ô∏è  Keep this notebook running!\")\n",
    "print(\"    The server will stop when the notebook disconnects.\")\n",
    "print(\"\\nüí° Tips:\")\n",
    "print(f\"    - Test the server: GET {public_url}/\")\n",
    "print(f\"    - Health check: GET {public_url}/health\")\n",
    "print(f\"    - Clone voice: POST {public_url}/clone\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Run server (Colab-compatible method)\n",
    "config = uvicorn.Config(app, host=\"0.0.0.0\", port=PORT, log_level=\"info\")\n",
    "server = uvicorn.Server(config)\n",
    "await server.serve()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
